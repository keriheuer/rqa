{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from surrogates import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "df = pd.read_csv('1ES_binned_lc.csv')\n",
    "pred_df = pd.read_csv('1ES_pred_DHO_lc.csv')\n",
    "\n",
    "lc, pred_lc = df['scaled lumin'].values, pred_df['lumin'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate a time series (replace with your actual data)\n",
    "np.random.seed(0)\n",
    "# ts = np.random.normal(size=100)\n",
    "\n",
    "# Create surrogates\n",
    "white_surrogates = white_noise_surrogates(ts)\n",
    "correlated_surrogates = correlated_noise_surrogate(ts)\n",
    "IAAFT_surrogates = IAAFT_surrogates(ts)\n",
    "\n",
    "\n",
    "# Call the plotting function\n",
    "surrogate_data = {'white': white_surrogates, 'correlated': correlated_surrogates, 'IAAFT': IAAFT_surrogates}\n",
    "plot_time_series_and_spectrum(ts, surrogate_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Generate a time series (replace with your actual data)\n",
    "np.random.seed(0)\n",
    "ts = np.random.normal(size=1000)\n",
    "\n",
    "# Create surrogates\n",
    "white_surrogates = white_noise_surrogates(ts)\n",
    "correlated_surrogates = correlated_noise_surrogate(ts)\n",
    "# IAAFT_surrogates = IAAFT_surrogates(ts)\n",
    "\n",
    "# Call the plotting function\n",
    "surrogate_data = {\n",
    "    'White Noise Surrogates': white_surrogates,\n",
    "    'Correlated Noise Surrogates': correlated_surrogates,\n",
    "    # 'IAAFT Surrogates': IAAFT_surrogates \n",
    "}\n",
    "plot_amplitude_and_spectrum(ts, surrogate_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import correlate\n",
    "\n",
    "\n",
    "# Example time series \n",
    "ts = np.random.normal(size=100)\n",
    "\n",
    "# Compute autocorrelation\n",
    "auto_corr_original = autocorrelation(ts)\n",
    "\n",
    "# Generate Fourier transform surrogate\n",
    "surrogate = correlated_noise_surrogate(ts)\n",
    "\n",
    "# Compute autocorrelation of the surrogate\n",
    "auto_corr_fourier = autocorrelation(surrogate)\n",
    "\n",
    "auto_corr_white = autocorrelation(white_noise_surrogates(ts))\n",
    "\n",
    "# Plot the autocorrelation functions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(auto_corr_original, label='Original', alpha=0.7)\n",
    "plt.plot(auto_corr_fourier, label='Fourier Surrogate', alpha=0.7)\n",
    "plt.plot(auto_corr_white, label='White Noise Surrogate', alpha=0.7)\n",
    "plt.title('Autocorrelation Function')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Noise Surrogates Shape: (10, 100)\n",
      "Correlated Noise Surrogates Shape: (10, 100)\n",
      "IAAFT Surrogates Shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "ts = np.random.randn(100) \n",
    "N = 10  # Number of surrogates\n",
    "\n",
    "# Generate surrogates\n",
    "white_noise = white_noise_surrogates(ts, N)\n",
    "correlated_noise = correlated_noise_surrogate(ts, N)\n",
    "IAAFT = IAAFT_surrogates(ts, N)\n",
    "\n",
    "# The shape of each surrogate array will be (N, len(ts))\n",
    "print(\"White Noise Surrogates Shape:\", white_noise.shape)\n",
    "print(\"Correlated Noise Surrogates Shape:\", correlated_noise.shape)\n",
    "print(\"IAAFT Surrogates Shape:\", IAAFT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d: -0.01334958586569371\n",
      "Mann-Whitney U Test p-value: 0.5383041808591436\n",
      "KS Test p-value: 0.4659595288557257\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu, ks_2samp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ts = np.random.randn(1000)  \n",
    "surrogate = np.random.randn(1000)\n",
    "\n",
    "# Calculate the effect size\n",
    "d = cohens_d(ts, surrogate)\n",
    "\n",
    "# Calculate the Mann-Whitney U test and KS test\n",
    "stat, p_value_mw = mannwhitneyu(ts, surrogate)\n",
    "stat, p_value_ks = ks_2samp(ts, surrogate)\n",
    "\n",
    "print(f\"Cohen's d: {d}\")\n",
    "print(f\"Mann-Whitney U Test p-value: {p_value_mw}\")\n",
    "print(f\"KS Test p-value: {p_value_ks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Define the worker function for parallel execution\n",
    "def worker(ts):\n",
    "    G = get_visibility_graph(ts)  # Convert time series to visibility graph\n",
    "    return compute_basic_graph_measures(G)\n",
    "\n",
    "# Define a function to execute the computation in parallel\n",
    "def compute_measures_parallel(ts_array, num_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(worker, ts_array))\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming white_noise_surrogates is an array of shape (100, T)\n",
    "surrogates = phase_randomized_surrogates(ts, 100)\n",
    "\n",
    "# Compute graph measures for all surrogates in parallel and store in DataFrame\n",
    "measures_df = compute_measures_parallel(surrogates)\n",
    "print(measures_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare surrogate measures to original data's measures\n",
    "\n",
    "def get_pvalues(measures_df, original_measures, larger_is_better=None):\n",
    "    \"\"\"\n",
    "    Calculate p-values for each measure of the original time series.\n",
    "\n",
    "    :param measures_df: DataFrame where each row is a surrogate and each column is a measure.\n",
    "    :param original_measures: Dictionary of measures for the original time series.\n",
    "    :param larger_is_better: Boolean indicating whether larger values of the measure indicate stronger structure.\n",
    "    :return: Dictionary of p-values for each measure.\n",
    "    \"\"\"\n",
    "    p_values = {}\n",
    "    num_surrogates = len(measures_df)\n",
    "    \n",
    "    if not larger_is_better: # no custom mapping supplied\n",
    "        larger_is_better = {\n",
    "            'number_of_nodes': False,  # Number of nodes is usually not directly related to better network structure/topology\n",
    "            'number_of_edges': False,  # Similar to number_of_nodes, not directly indicative of better structure\n",
    "            'average_degree': True,  # Higher average degree might indicate a more interconnected or robust network\n",
    "            'density': True,  # Higher density can indicate a more interconnected network\n",
    "            'average_clustering_coefficient': True,  # Higher clustering can indicate a more tightly knit, community-like structure\n",
    "            'average_shortest_path_length': False,  # Shorter path lengths can indicate a more efficient or 'small-world' network\n",
    "            'diameter': False,  # Similar to average_shortest_path_length, a smaller diameter can indicate efficiency\n",
    "            'assortativity_coefficient': True,  # Higher assortativity can indicate that nodes preferentially attach to similar nodes, \n",
    "                                                # might be a sign of robustness in some networks\n",
    "        }\n",
    "        \n",
    "    for measure in original_measures:\n",
    "        sorted_values = sorted(measures_df[measure])\n",
    "        original_value = original_measures[measure]\n",
    "        \n",
    "        # Find the number of surrogates that have a smaller (or larger) value than the original\n",
    "        if larger_is_better[measure]:\n",
    "            count = sum(value > original_value for value in sorted_values)\n",
    "        else:\n",
    "            count = sum(value < original_value for value in sorted_values)\n",
    "        \n",
    "        # Calculate the empirical p-value\n",
    "        p_value = count / num_surrogates\n",
    "        p_values[measure] = p_value\n",
    "    \n",
    "    return p_values\n",
    "\n",
    "def get_significance(p_values):\n",
    "    \"\"\"\n",
    "    Interpret the p-values and print out the significance level for each measure.\n",
    "\n",
    "    :param p_values: Dictionary of p-values for each measure.\n",
    "    \"\"\"\n",
    "    for measure, p in p_values.items():\n",
    "        if p < 0.05:\n",
    "            print(f\"{measure}: significant (p = {p:.3f})\")\n",
    "        elif 0.05 <= p < 0.1:\n",
    "            print(f\"{measure}: moderately significant (p = {p:.3f})\")\n",
    "        else:\n",
    "            print(f\"{measure}: not significant (p = {p:.3f})\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'original_measures' is a dictionary containing the measures for the original time series\n",
    "# And 'measures_df' is the DataFrame returned from the compute_measures_parallel function\n",
    "original_measures = compute_basic_graph_measures(G) \n",
    "p_values = get_pvalues(measures_df, original_measures)\n",
    "get_significance(p_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation over the range of recurrence rates for each surrogate\n",
    "mean_rqa = rqa_df.groupby('surrogate_id').mean()\n",
    "std_rqa = rqa_df.groupby('surrogate_id').std()\n",
    "\n",
    "# Compute the 25th and 75th percentiles for each surrogate\n",
    "q1_rqa = rqa_df.groupby('surrogate_id').quantile(0.25)\n",
    "q3_rqa = rqa_df.groupby('surrogate_id').quantile(0.75)\n",
    "\n",
    "# Compute the interquartile range (IQR) for each RQA metric and each surrogate\n",
    "iqr_rqa = q3_rqa - q1_rqa\n",
    "\n",
    "print(mean_rqa)\n",
    "print(std_rqa)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
